\section{Malware Erkennung Umgehung}
\label{Sec:MalwareEvasion}
Viele kommerzielle Systeme arbeiten auch heute noch hauptsächlich signaturbasiert und erkennen keine neue Malware oder dies nur unzuverlässig mittels Heuristiken \cite{rathore_2023_breaking}, während Malwareautoren bereits kompliziertere Verfahren einführen, um die Analyse und Erkennung weiter zu erschweren \cite{nunes_2022_bane}. Dies vereinfacht ihre Arbeit, da sie dann nicht immer neue Tools entwickeln müssen, welche noch nicht von Sicherheitsforschern gefunden und katalogisiert wurden \cite{holm_2023_hide}. Um das automatisiert umzusetzen, gibt es eine Vielfalt von Tools zur Umgehung von Malware-Erkennung oder zur Fehlklassifikation von Malwarefiles.

\subsection{Obfuskatorarten}
Die Methoden zur Umgehung von AV-Software lassen sich grob in drei große Bereiche aufteilen: Transformationsbasierte, Verschleierungsbasierte und Angriffsbasierte Strategien \cite{geng_2024_a}
\textit{Verschleierungsbasierte} Strategien basieren darauf, dass die Erkennungsleistung erschwert wird, in dem beispielsweise die Virtualisierung oder das Sandboxing erkannt wird; ebenso möglich sind das Hinzufügen von langer Inaktivität  oder die Erkennung von menschlicher Präsenz, sodass eine Ausführung in einem Analysesetting nicht zu illegalem Verhalten der Malware führt, sondern sie sich in der Analyse wie Goodware verhält \cite{geng_2024_a}. Zusammen mit der \textit{Angriffsbasierten} Strategie wird sie manchmal auch unter dem Schlagwort Polymorphie \cite{elsersy_2022_the} zusammengefasst. Diese Strategie versucht aktiv gegen AV Software vorzugehen, indem sie die Prozesse beispielsweise beendet oder überlastet und so eine Klassifikation erschwert \cite{geng_2024_a}. 
Auf der anderen Seite und unter dem Schlagwort von \textit{metarmorphie} \cite{elsersy_2022_the} steht die \textit{Transformationsbasierte} Strategie, welche Obfuskatoren und Packer im klassischen Sinne, wie Nymcrypt2 und Inceptor beinhaltet. Diese verändern in der Regel nichts am Verhalten von Malware \cite{wauters_2024_building}, sondern sorgen dafür, dass sie andere Strukturen und damit Signaturen aufweisen, was die Klassifikation natürlich erschwert \cite{geng_2024_a}.

\subsubsection{Obfuskationseinordnung}
\subsubsection{Übersicht von 'Kommerziellen' Obfuskatoren}
\paragraph{Malware}
\paragraph{Intellectual Property}

\subsection{Varianten Erstellung}
Die Erstellung von Malwarevarianten ist in der Literatur ein bekanntes Thema, welches auch abseits von den 'kommerziellen' Obfuskationstools verwendet wird. Ein häufiger Anwendungsfall dafür ist die Verbesserung von AV Software durch das trainieren von ML Klassifikatoren\cite{phan_2022_leveraging}. So wurden zur Variantengerierung Codecaves erfolgreich in die Malwarebinary eingefügt und die Werte in diesen dann solange variert, bis sie von AV Software nicht mehr erkannt wurde \cite{yuste_2022_optimization}. Die benötigte Zeit und das Problem von Korrupten Binaries war auch schon in \cite{castro_2019_armed} prävalent, wodurch sich ergeben hatte, dass nur wenige Veränderungen notwendig sind, um eine Evasion herbeizuführen. So waren dennoch nur 18\% der erzeugten Files überhaupt ausfühbar und der Algorithmus benötigte 5 Minuten für die Generation einer Variante \cite{castro_2019_armed}.

Ein Ansatz, der erst durch das Erstarken von Large Language Models in der Forschung und Technologie möglich wurde, ist die Anwendung dieser LLMs um Code in funktional identische Varianten zu übersetzen und so Malwarevarianten zu generieren. Dabei ist es nichtmal nötig spezifische LLMs zu trainieren, da die kommerziellen und free to use Tools bereits die  gängigen Programmiersprachen von Haus aus verwenden können \cite{madani_2023_metamorphic}.
\subsection{Adversarial Attacks}
Aus diesem Bereich erstand dann auch der Forschungsbereich zur Generation von Malwarevarianten \cite{jin_2023_on}. Diese fokussieren sich darauf, durch Veränderungen an den Malwarefiles, bei gleichbleibender Funktion, neue Ausprägungen von Malware zu finden. Hierbei lässt sich sich Code Cave Optimization nennen, welche Padding Bereiche in PE-Files\footnote{Windows Portable Executable} verschieben und die Werte darin zu verändern, um eine Missklassifikation herbeizuführen \cite{yuste_2022_optimization}. Ähnliche Ansätze sind im Bereich der Adversarial Attacks vorhanden, welche Ursprünglich aus dem Bilderkennungsbereich entstanden ist. Hierbei geht es darum, dass ein gegebes File (beispielsweise das Bild eines Tucans) so verändert wird, dass ein trainierter Klassifikator (Computer Vision something), dass durch minimale Veränderung eine Fehlklassifikation herbeigeführt wird. So wird das Bild von dem Tukan plötzlich als Katze erkannt, obwohl für den menschlichen Beobachter keine Veränderung ersichtlich ist \cite{demetrio_2024_formalizing}. Dieses Verfahren wurde schließlich auch für die Malwareforschung übernommen und als Angriffsweg auf Machinelearning Klassifikatoren eingesetzt \cite{demetrio_2021_functionalitypreserving}. Dabei hat sich gezeigt, dass dieser Angriff für White-Box Modelle ausgesprochen effizient ist und für Black-Box Angriffe - also beispielsweise für kommerzielle Software - aufwändiger ist \cite{yuste_2022_optimization}. Aus diesem Grund werden für das Suchproblem von Adversarial Examples oder Permutationen häufig genetische Algorithmen verwendet \cite{demetrio_2021_functionalitypreserving}, da diese in kurzer Zeit einen großen Suchbereich abdecken können. \label{adversarial_example}
